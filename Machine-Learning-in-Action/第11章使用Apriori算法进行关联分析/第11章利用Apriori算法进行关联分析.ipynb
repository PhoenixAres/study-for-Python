{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 关联分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从大规模数据集中寻找物品间的隐含关系被称作关联分析(association analysis)或者关联规则学习(association rule learning)。\n",
    "\n",
    "这些关系可以有两种形式：频繁项集或者关联规则，频繁项集(frequent item sets)是经常出现在一块的物品的集合，关联规则(association rules)暗示两种物品之间可能存在很强的关系。\n",
    "\n",
    "一个项集的支持度(support)被定义为数据集中包含该项集的记录所占的比例，支持度是针对项集而言的，因此可以定义一个最小支持度，而只保留满足最小支持度的项集。\n",
    "\n",
    "可信度或置信度(confidence)是针对关联规则来定义的，是量化关联分析是否成功的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Apriori原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apriori原理是说如果某个项集是频繁的，那么它的所有子集也是频繁的，我们经常运用其逆否命题，即：\n",
    "\n",
    "如果一个项集是非频繁集，那么它的所有超集也是非频繁的。使用该原理就可以避免项集数目的指数增长，从而在合理时间内计算出频繁项集。\n",
    "\n",
    "Apriori算法：\n",
    "\n",
    "优点：易编码实现\n",
    "\n",
    "缺点：在大数据集上可能较慢\n",
    "\n",
    "适用数据类型：数值型或者标称型数据\n",
    "\n",
    "Apriori算法的一般过程：\n",
    "\n",
    "（1）收集数据：使用任意方法\n",
    "\n",
    "（2）准备数据：任何数据类型都可以，因为只保存集合\n",
    "\n",
    "（3）分析数据：使用任意方法\n",
    "\n",
    "（4）训练算法：使用Apriori算法来找到频繁项集\n",
    "\n",
    "（5）测试算法：不需要测试过程\n",
    "\n",
    "（6）使用算法：用于发现频繁项集以及物品之间的关联规则"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 使用Apriori算法来发现频繁集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apriori算法的两个输入参数分别是最小支持度和数据集，该算法首先会生成所有单个物品的项集列表，接着扫描交易记录去掉不满足最小支持度要求的项集。\n",
    "\n",
    "然后，对剩下来的集合进行组合以生成包含两个元素的项集，接下来，再重新扫描交易记录，去掉不满足最小支持度的项集，重复该过程直至所有项集被去掉。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 生成候选项集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "伪代码如下：\n",
    "\n",
    "    对数据集中的每条交易记录tran\n",
    "    对每个候选项集can：\n",
    "        检查一下can是否是tran的子集：\n",
    "        如果是，则增加can的计数值\n",
    "    对每个候选项集：\n",
    "    如果其支持度不低于最小值，则保留该项集\n",
    "    返回所有频繁项集列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import *\n",
    "\n",
    "def loadDataSet():\n",
    "    return [[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]]\n",
    "\n",
    "def createC1(dataSet):\n",
    "    C1 = []\n",
    "    for transaction in dataSet:\n",
    "        for item in transaction:\n",
    "            if not [item] in C1:\n",
    "                C1.append([item])\n",
    "    C1.sort()\n",
    "    return list(map(frozenset, C1))      #对C1中每个项构建一个不变集合\n",
    "\n",
    "def scanD(D, Ck, minSupport):\n",
    "    ssCnt = {}\n",
    "    for tid in D:\n",
    "        for can in Ck:\n",
    "            if can.issubset(tid):\n",
    "                ssCnt[can] = ssCnt.get(can, 0) + 1\n",
    "    numItems = float(len(D))\n",
    "    retList = []\n",
    "    supportData = {}\n",
    "    for key in ssCnt:\n",
    "        support = ssCnt[key] / numItems      #计算所有项集的支持度\n",
    "        if support >= minSupport:\n",
    "            retList.insert(0, key)\n",
    "        supportData[key] = support\n",
    "    return retList, supportData\n",
    "\n",
    "dataSet = loadDataSet()\n",
    "dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[frozenset({1}),\n",
       " frozenset({2}),\n",
       " frozenset({3}),\n",
       " frozenset({4}),\n",
       " frozenset({5})]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C1 = createC1(dataSet)\n",
    "C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{1, 3, 4}, {2, 3, 5}, {1, 2, 3, 5}, {2, 5}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = list(map(set, dataSet))\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[frozenset({5}), frozenset({2}), frozenset({3}), frozenset({1})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1, suppData0 = scanD(D, C1, 0.5)\n",
    "L1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述4个项集构成了L1列表，该列表中的每个单物品项集至少出现在50%以上的记录中，由于物品4没有达到最小支持度，所以被丢弃。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 组织完整的Apriori算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "伪代码如下：\n",
    "\n",
    "    当集合中项的个数大于0时\n",
    "        构建一个k个项组成的候选项集的列表\n",
    "        检查数据以确认每个项集都是频繁的\n",
    "        保留频繁项集并构建k+1项组成的候选项集的列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[frozenset({5}), frozenset({2}), frozenset({3}), frozenset({1})],\n",
       " [frozenset({2, 3}), frozenset({3, 5}), frozenset({2, 5}), frozenset({1, 3})],\n",
       " [frozenset({2, 3, 5})],\n",
       " []]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def aprioriGen(Lk, k):\n",
    "    retList = []\n",
    "    lenLk = len(Lk)\n",
    "    for i in range(lenLk):\n",
    "        for j in range(i+1, lenLk):\n",
    "            L1 = list(Lk[i])[:k-2]\n",
    "            L2 = list(Lk[j])[:k-2]\n",
    "            if L1 == L2:                        #前k-2个项相同时，将两个集合合并\n",
    "                retList.append(Lk[i] | Lk[j])\n",
    "    return retList\n",
    "\n",
    "def apriori(dataSet, minSupport = 0.5):\n",
    "    C1 = createC1(dataSet)\n",
    "    D = list(map(set, dataSet))\n",
    "    L1, supportData = scanD(D, C1, minSupport)\n",
    "    L = [L1]\n",
    "    k = 2\n",
    "    while len(L[k-2]) > 0:\n",
    "        Ck = aprioriGen(L[k-2], k)\n",
    "        Lk, supK = scanD(D, Ck, minSupport)     #扫描数据集，从Ck得到Lk\n",
    "        supportData.update(supK)\n",
    "        L.append(Lk)\n",
    "        k += 1\n",
    "    return L, supportData\n",
    "\n",
    "dataSet = loadDataSet()\n",
    "L, suppData = apriori(dataSet)\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[frozenset({2, 5}),\n",
       " frozenset({3, 5}),\n",
       " frozenset({1, 5}),\n",
       " frozenset({2, 3}),\n",
       " frozenset({1, 2}),\n",
       " frozenset({1, 3})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aprioriGen(L[0], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[frozenset({5}), frozenset({2}), frozenset({3})], [frozenset({2, 5})], []]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L, suppData = apriori(dataSet, minSupport=0.7)\n",
    "L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 从频繁项集中挖掘关联规则"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一条规则$P -> H$的可信度定义为：\n",
    "\n",
    "$$ \\frac {support(P | H)} {support(P)} $$\n",
    "\n",
    "其中，P | H 表示集合P与H的并集\n",
    "\n",
    "为找到感兴趣的规则，我们先生成一个可能的规则列表，然后测试每条规则的可信度，如果可信度不满足最小要求，则去掉该规则。\n",
    "\n",
    "类似于频繁项集的生成，如果某条规则并不满足最小可信度要求，那么该规则的所有子集也不会满足最小可信度的要求。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({5}) --> frozenset({2}) conf: 1.0\n",
      "frozenset({2}) --> frozenset({5}) conf: 1.0\n",
      "frozenset({1}) --> frozenset({3}) conf: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(frozenset({5}), frozenset({2}), 1.0),\n",
       " (frozenset({2}), frozenset({5}), 1.0),\n",
       " (frozenset({1}), frozenset({3}), 1.0)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calcConf(freqSet, H, supportData, br1, minConf = 0.7):\n",
    "    prunedH = []\n",
    "    for conseq in H:\n",
    "        conf = supportData[freqSet] / supportData[freqSet - conseq]\n",
    "        if conf >= minConf:\n",
    "            print(freqSet - conseq, '-->', conseq, 'conf:', conf)\n",
    "            br1.append((freqSet - conseq, conseq, conf))\n",
    "            prunedH.append(conseq)\n",
    "    return prunedH\n",
    "\n",
    "def rulesFromConseq(freqSet, H, supportData, br1, minConf = 0.7):\n",
    "    m = len(H[0])\n",
    "    if len(freqSet) > m + 1:          #尝试进一步合并\n",
    "        Hmp1 = aprioriGen(H, m + 1)   #创建Hm+1条新候选规则\n",
    "        Hmp1 = calcConf(freqSet, Hmp1, supportData, br1, minConf)\n",
    "        if len(Hmp1) > 1:\n",
    "            rulesFromConseq(freqSet, Hmp1, supportData, br1, minConf)\n",
    "\n",
    "def generateRules(L, supportData, minConf = 0.7):\n",
    "    bigRuleList = []\n",
    "    for i in range(1, len(L)):    #只获取有两个或更多元素的集合\n",
    "        for freqSet in L[i]:\n",
    "            H1 = [frozenset([item]) for item in freqSet]\n",
    "            if i > 1:\n",
    "                rulesFromConseq(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "            else:\n",
    "                calcConf(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "    return bigRuleList\n",
    "\n",
    "dataSet = loadDataSet()\n",
    "L, suppData = apriori(dataSet, minSupport=0.5)\n",
    "rules = generateRules(L, suppData, minConf=0.7)\n",
    "rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面降低可信度阈值之后看一下结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({3}) --> frozenset({2}) conf: 0.6666666666666666\n",
      "frozenset({2}) --> frozenset({3}) conf: 0.6666666666666666\n",
      "frozenset({5}) --> frozenset({3}) conf: 0.6666666666666666\n",
      "frozenset({3}) --> frozenset({5}) conf: 0.6666666666666666\n",
      "frozenset({5}) --> frozenset({2}) conf: 1.0\n",
      "frozenset({2}) --> frozenset({5}) conf: 1.0\n",
      "frozenset({3}) --> frozenset({1}) conf: 0.6666666666666666\n",
      "frozenset({1}) --> frozenset({3}) conf: 1.0\n",
      "frozenset({5}) --> frozenset({2, 3}) conf: 0.6666666666666666\n",
      "frozenset({3}) --> frozenset({2, 5}) conf: 0.6666666666666666\n",
      "frozenset({2}) --> frozenset({3, 5}) conf: 0.6666666666666666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(frozenset({3}), frozenset({2}), 0.6666666666666666),\n",
       " (frozenset({2}), frozenset({3}), 0.6666666666666666),\n",
       " (frozenset({5}), frozenset({3}), 0.6666666666666666),\n",
       " (frozenset({3}), frozenset({5}), 0.6666666666666666),\n",
       " (frozenset({5}), frozenset({2}), 1.0),\n",
       " (frozenset({2}), frozenset({5}), 1.0),\n",
       " (frozenset({3}), frozenset({1}), 0.6666666666666666),\n",
       " (frozenset({1}), frozenset({3}), 1.0),\n",
       " (frozenset({5}), frozenset({2, 3}), 0.6666666666666666),\n",
       " (frozenset({3}), frozenset({2, 5}), 0.6666666666666666),\n",
       " (frozenset({2}), frozenset({3, 5}), 0.6666666666666666)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules = generateRules(L, suppData, minConf=0.5)\n",
    "rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，一旦降低可信度阈值，就可以获得更多的规则。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 示例：发现毒蘑菇的相似特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有时候我们并不想寻找所有的频繁项集，而只对包含某个特定元素项的项集感兴趣。\n",
    "\n",
    "例如，我们会寻找毒蘑菇的一些公共特征，利用这些特征就能避免吃到那些有毒的蘑菇。\n",
    "\n",
    "在数据集中，第一个特征表示有毒或者可食用，如果样本有毒，则值为2，如果可食用，则值为1。\n",
    "\n",
    "为了找到毒蘑菇中存在的公共特征，可以寻找包含特征值为2的频繁项集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'28', '2'})\n",
      "frozenset({'2', '53'})\n",
      "frozenset({'23', '2'})\n",
      "frozenset({'34', '2'})\n",
      "frozenset({'36', '2'})\n",
      "frozenset({'2', '59'})\n",
      "frozenset({'2', '63'})\n",
      "frozenset({'67', '2'})\n",
      "frozenset({'2', '76'})\n",
      "frozenset({'85', '2'})\n",
      "frozenset({'2', '86'})\n",
      "frozenset({'90', '2'})\n",
      "frozenset({'2', '93'})\n",
      "frozenset({'39', '2'})\n"
     ]
    }
   ],
   "source": [
    "mushDatSet = []\n",
    "with open('mushroom.dat') as f:\n",
    "    mushDatSet = [line.split() for line in f.readlines()]\n",
    "L, suppData = apriori(mushDatSet, minSupport=0.3)\n",
    "for item in L[1]:\n",
    "    if item.intersection('2'):\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以对更大的项集重复上述过程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in L[3]:\n",
    "    if item.intersection('2'):\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，需要观察这些特征，以便了解蘑菇的特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow2.1]",
   "language": "python",
   "name": "conda-env-tensorflow2.1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
